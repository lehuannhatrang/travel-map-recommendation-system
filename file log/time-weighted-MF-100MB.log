
################################################################################
user-based = 1 ( ~ user-based)
################################################################################

K = 50, lam = .1, learning_rate = 0.75, max_iter = 300, user_based = 1

iter = 10 , loss = 34.36608230272306 , RMSE train = 1.7757872327370938
iter = 20 , loss = 15.732251567555798 , RMSE train = 1.2131074432315319
iter = 30 , loss = 7.576269360472164 , RMSE train = 1.1829340559461319
iter = 40 , loss = 3.8526057744837297 , RMSE train = 1.1824489219398586
iter = 50 , loss = 2.145546635595654 , RMSE train = 1.1826742818453673
iter = 60 , loss = 1.362670806428357 , RMSE train = 1.1827499259439394
iter = 70 , loss = 1.0036287843123948 , RMSE train = 1.1827699887511127
iter = 80 , loss = 0.8389667559887378 , RMSE train = 1.1827750044482204
iter = 90 , loss = 0.763450709137125 , RMSE train = 1.1827762237618162
iter = 100 , loss = 0.7288181242758038 , RMSE train = 1.1827765147524603
iter = 110 , loss = 0.7129351461857367 , RMSE train = 1.1827765832412054
iter = 120 , loss = 0.7056509570070489 , RMSE train = 1.1827765991850698
iter = 130 , loss = 0.7023102895834165 , RMSE train = 1.1827766028637152
iter = 140 , loss = 0.7007781854267481 , RMSE train = 1.182776603706215
iter = 150 , loss = 0.700075523341911 , RMSE train = 1.1827766038979666
iter = 160 , loss = 0.6997532621390617 , RMSE train = 1.182776603941368
iter = 170 , loss = 0.6996054626731311 , RMSE train = 1.1827766039511556
iter = 180 , loss = 0.6995376765041419 , RMSE train = 1.1827766039533547
iter = 190 , loss = 0.699506587075569 , RMSE train = 1.1827766039538474
iter = 200 , loss = 0.6994923281155182 , RMSE train = 1.1827766039539533
iter = 210 , loss = 0.6994857882854217 , RMSE train = 1.1827766039539724
iter = 220 , loss = 0.6994827887871321 , RMSE train = 1.1827766039539762
iter = 230 , loss = 0.6994814130535043 , RMSE train = 1.1827766039539764
iter = 240 , loss = 0.6994807820617096 , RMSE train = 1.1827766039539775
iter = 250 , loss = 0.6994804926495733 , RMSE train = 1.1827766039539784
iter = 260 , loss = 0.6994803599060048 , RMSE train = 1.1827766039539784
iter = 270 , loss = 0.6994802990204864 , RMSE train = 1.1827766039539784
iter = 280 , loss = 0.6994802710938679 , RMSE train = 1.1827766039539784
iter = 290 , loss = 0.6994802582845332 , RMSE train = 1.1827766039539784
iter = 300 , loss = 0.6994802524091156 , RMSE train = 1.1827766039539784

User-based MF, RMSE = 1.3584726568765555

################################################################################

K = 50, lam = .1, learning_rate = 0.1, max_iter = 300, user_based = 1

iter = 10 , loss = 81.27566826189475 , RMSE train = 3.6608871396332194
iter = 20 , loss = 69.50014098022021 , RMSE train = 3.3636502471640277
iter = 30 , loss = 60.30863611687573 , RMSE train = 3.045374367921338
iter = 40 , loss = 52.917394727648635 , RMSE train = 2.7228531268180163
iter = 50 , loss = 46.822028056534705 , RMSE train = 2.4163134235728747
iter = 60 , loss = 41.68966104013495 , RMSE train = 2.1428042221789405
iter = 70 , loss = 37.29515006871216 , RMSE train = 1.9112199540088246
iter = 80 , loss = 33.48237863617135 , RMSE train = 1.720510232230008
iter = 90 , loss = 30.140270761846775 , RMSE train = 1.5690475537397353
iter = 100 , loss = 27.18766129201368 , RMSE train = 1.4534750693825582
iter = 110 , loss = 24.56360652693726 , RMSE train = 1.3686016642852354
iter = 120 , loss = 22.22109371621173 , RMSE train = 1.308265147718782
iter = 130 , loss = 20.12290443584428 , RMSE train = 1.2663852137759246
iter = 140 , loss = 18.238859599040914 , RMSE train = 1.2377636523146547
iter = 150 , loss = 16.54396025587381 , RMSE train = 1.2184781478740854
iter = 160 , loss = 15.017114863041979 , RMSE train = 1.205607361742543
iter = 170 , loss = 13.64025409078673 , RMSE train = 1.1971016111143526
iter = 180 , loss = 12.397704103804728 , RMSE train = 1.191531721169273
iter = 190 , loss = 11.27573393222699 , RMSE train = 1.187921711055832
iter = 200 , loss = 10.26222136791044 , RMSE train = 1.1856117873686973
iter = 210 , loss = 9.346400548410294 , RMSE train = 1.1841590094960237
iter = 220 , loss = 8.518666638556489 , RMSE train = 1.1832668630582956
iter = 230 , loss = 7.770421075306244 , RMSE train = 1.1827348004747897
iter = 240 , loss = 7.093946168006402 , RMSE train = 1.1824357004240926
iter = 250 , loss = 6.48230138580626 , RMSE train = 1.182284406422292
iter = 260 , loss = 5.929236028114043 , RMSE train = 1.1822244496869232
iter = 270 , loss = 5.429114561589307 , RMSE train = 1.1822194439715115
iter = 280 , loss = 4.976851979735518 , RMSE train = 1.1822457998952471
iter = 290 , loss = 4.56785727086927 , RMSE train = 1.1822885404000543
iter = 300 , loss = 4.197983580848579 , RMSE train = 1.1823383361319713

User-based MF, RMSE = 1.3589234028613084

################################################################################

K = 100, lam = .1, learning_rate = 0.75, max_iter = 300, user_based = 1


################################################################################

K = 100, lam = .1, learning_rate = 0.1, max_iter = 300, user_based = 1

iter = 10 , loss = 116.21221330076064 , RMSE train = 4.040539712095489

################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 50, lam = .1, learning_rate = 0.75, max_iter = 300, user_based = 0

iter = 10 , loss = 34.32956005863617 , RMSE train = 1.7642583260134608
iter = 20 , loss = 15.718994643502022 , RMSE train = 1.2063174128549414
iter = 30 , loss = 7.566464918749723 , RMSE train = 1.1765963385880114
iter = 40 , loss = 3.8440647191401998 , RMSE train = 1.1761140332252376
iter = 50 , loss = 2.1375737235490857 , RMSE train = 1.176332277157468
iter = 60 , loss = 1.3549600509033128 , RMSE train = 1.176405412498797
iter = 70 , loss = 0.9960392765222146 , RMSE train = 1.176424761356366
iter = 80 , loss = 0.8314333159034878 , RMSE train = 1.1764295887675031
iter = 90 , loss = 0.7559431971030102 , RMSE train = 1.1764307604745796
iter = 100 , loss = 0.721322608499734 , RMSE train = 1.1764310397603344
iter = 110 , loss = 0.7054451854926483 , RMSE train = 1.1764311054287946
iter = 120 , loss = 0.6981635714138017 , RMSE train = 1.1764311207033944
iter = 130 , loss = 0.6948240990860582 , RMSE train = 1.1764311242251198
iter = 140 , loss = 0.6932925502393334 , RMSE train = 1.1764311250311585
iter = 150 , loss = 0.6925901464964098 , RMSE train = 1.1764311252145132
iter = 160 , loss = 0.6922680056236783 , RMSE train = 1.176431125255997
iter = 170 , loss = 0.6921202622705432 , RMSE train = 1.1764311252653419
iter = 180 , loss = 0.692052502298018 , RMSE train = 1.17643112526743
iter = 190 , loss = 0.6920214251128091 , RMSE train = 1.1764311252679012
iter = 200 , loss = 0.692007171880967 , RMSE train = 1.1764311252680122
iter = 210 , loss = 0.6920006347336033 , RMSE train = 1.1764311252680342
iter = 220 , loss = 0.691997636492963 , RMSE train = 1.1764311252680393
iter = 230 , loss = 0.6919962613494658 , RMSE train = 1.1764311252680413
iter = 240 , loss = 0.6919956306348247 , RMSE train = 1.1764311252680413
iter = 250 , loss = 0.6919953413529633 , RMSE train = 1.1764311252680415
iter = 260 , loss = 0.6919952086706803 , RMSE train = 1.1764311252680415
iter = 270 , loss = 0.691995147814015 , RMSE train = 1.1764311252680415
iter = 280 , loss = 0.6919951199009906 , RMSE train = 1.1764311252680415
iter = 290 , loss = 0.691995107098065 , RMSE train = 1.1764311252680415
iter = 300 , loss = 0.6919951012256711 , RMSE train = 1.1764311252680415

User-based MF, RMSE = 3.0241458900339366

################################################################################

K = 100, lam = .1, learning_rate = 0.75, max_iter = 300, user_based = 0



################################################################################

K = 50, lam = .1, learning_rate = 0.75, max_iter = 300, user_based = 0

