
kh√¥ng edit totalLike: 

################################################################################
user-based = 1 ( ~ user-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 1

iter = 10 , loss = 60.45031150911842 , RMSE train = 3.557638028247554
iter = 20 , loss = 50.90987691912065 , RMSE train = 3.240753263623348
iter = 30 , loss = 43.69187143577279 , RMSE train = 2.9215658237364925
iter = 40 , loss = 38.0276588226767 , RMSE train = 2.6120290229059204
iter = 50 , loss = 33.44931116465833 , RMSE train = 2.3259006957804713
iter = 60 , loss = 29.657588333792432 , RMSE train = 2.0726342026333144
iter = 70 , loss = 26.454485426791656 , RMSE train = 1.8591221634991135
iter = 80 , loss = 23.705260416035372 , RMSE train = 1.6837877998031163
iter = 90 , loss = 21.315811293298914 , RMSE train = 1.5435630101105844
iter = 100 , loss = 19.218707774487434 , RMSE train = 1.4357415728242149
iter = 110 , loss = 17.364353691943542 , RMSE train = 1.3563771660262862
iter = 120 , loss = 15.715293544387197 , RMSE train = 1.2997582133576377
iter = 130 , loss = 14.24249077191124 , RMSE train = 1.2604662523463128
iter = 140 , loss = 12.922863543013666 , RMSE train = 1.2336398977864316
iter = 150 , loss = 11.737633034502501 , RMSE train = 1.215515262716548
iter = 160 , loss = 10.671202260603126 , RMSE train = 1.2033975616064394
iter = 170 , loss = 9.710384546660169 , RMSE train = 1.1953529733172914
iter = 180 , loss = 8.84386441022136 , RMSE train = 1.1900545459282577
iter = 190 , loss = 8.061814251865666 , RMSE train = 1.186594322535509
iter = 200 , loss = 7.355616461300485 , RMSE train = 1.1843573706323152
iter = 210 , loss = 6.717657575322143 , RMSE train = 1.1829301328525081
iter = 220 , loss = 6.141172266497562 , RMSE train = 1.1820351542038385
iter = 230 , loss = 5.6201222713123 , RMSE train = 1.181488175765949
iter = 240 , loss = 5.149100211753211 , RMSE train = 1.1811665631784072
iter = 250 , loss = 4.723251481310783 , RMSE train = 1.1809893681359274
iter = 260 , loss = 4.338209511572862 , RMSE train = 1.180903318987372
iter = 270 , loss = 3.9900411724478446 , RMSE train = 1.1808734110117936
iter = 280 , loss = 3.6752000262098967 , RMSE train = 1.1808769097583267
iter = 290 , loss = 3.390485810231794 , RMSE train = 1.1808992027728245
iter = 300 , loss = 3.133008969410358 , RMSE train = 1.1809310219861144
iter = 310 , loss = 2.9001593658053073 , RMSE train = 1.1809666265770515
iter = 320 , loss = 2.6895785057075297 , RMSE train = 1.181002560903311
iter = 330 , loss = 2.49913477373898 , RMSE train = 1.1810368390808055
iter = 340 , loss = 2.3269012700399974 , RMSE train = 1.181068415318463
iter = 350 , loss = 2.1711359237548953 , RMSE train = 1.1810968318455886
iter = 360 , loss = 2.0302636130429415 , RMSE train = 1.1811219889248448
iter = 370 , loss = 1.9028600648732226 , RMSE train = 1.1811439958671532
iter = 380 , loss = 1.7876373410801651 , RMSE train = 1.1811630756279876
iter = 390 , loss = 1.6834307433828248 , RMSE train = 1.181179504702188
iter = 400 , loss = 1.5891869912400174 , RMSE train = 1.181193576145905
iter = 410 , loss = 1.5039535438472826 , RMSE train = 1.181205577636824
iter = 420 , loss = 1.4268689522090567 , RMSE train = 1.1812157792140119
iter = 430 , loss = 1.3571541396771596 , RMSE train = 1.1812244271571333
iter = 440 , loss = 1.2941045201044292 , RMSE train = 1.1812317416801816
iter = 450 , loss = 1.2370828721442746 , RMSE train = 1.1812379169213836
iter = 460 , loss = 1.1855128964833561 , RMSE train = 1.1812431222479054
iter = 470 , loss = 1.1388733901055046 , RMSE train = 1.1812475042482498
iter = 480 , loss = 1.0966929781944958 , RMSE train = 1.181251189019554
iter = 490 , loss = 1.0585453501002418 , RMSE train = 1.181254284509966
iter = 500 , loss = 1.0240449510075003 , RMSE train = 1.181256882775833

User-based MF, aMSE = 1.2518186013029746

################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 0

iter = 10 , loss = 10.818612172171228 , RMSE train = 1.1339916434618855
iter = 20 , loss = 5.117596213686923 , RMSE train = 0.9519195069720034
iter = 30 , loss = 2.5830096543510432 , RMSE train = 0.9423366855854047
iter = 40 , loss = 1.4243536729372441 , RMSE train = 0.9417454967326537
iter = 50 , loss = 0.8932210697432036 , RMSE train = 0.9416898946697917
iter = 60 , loss = 0.6496693560837408 , RMSE train = 0.9416824453471351
iter = 70 , loss = 0.5379822616323302 , RMSE train = 0.9416813209475089
iter = 80 , loss = 0.486764386227033 , RMSE train = 0.941681157986381
iter = 90 , loss = 0.463276546108368 , RMSE train = 0.9416811384263436
iter = 100 , loss = 0.452505289866801 , RMSE train = 0.9416811374019765
iter = 110 , loss = 0.4475656991623795 , RMSE train = 0.941681137842796
iter = 120 , loss = 0.4453004459056892 , RMSE train = 0.9416811380753785
iter = 130 , loss = 0.4442616177308628 , RMSE train = 0.941681138154175
iter = 140 , loss = 0.4437852176354396 , RMSE train = 0.9416811381771372
iter = 150 , loss = 0.44356674293947324 , RMSE train = 0.941681138183315
iter = 160 , loss = 0.4434665512596596 , RMSE train = 0.9416811381849209
iter = 170 , loss = 0.44342060359812163 , RMSE train = 0.9416811381853158
iter = 180 , loss = 0.44339953205013005 , RMSE train = 0.9416811381854192
iter = 190 , loss = 0.443389868631837 , RMSE train = 0.9416811381854399
iter = 200 , loss = 0.4433854369715402 , RMSE train = 0.9416811381854443
iter = 210 , loss = 0.4433834045979894 , RMSE train = 0.9416811381854452
iter = 220 , loss = 0.4433824725419206 , RMSE train = 0.9416811381854456
iter = 230 , loss = 0.4433820450951668 , RMSE train = 0.9416811381854462
iter = 240 , loss = 0.44338184906471456 , RMSE train = 0.9416811381854462
iter = 250 , loss = 0.44338175916327427 , RMSE train = 0.9416811381854462
iter = 260 , loss = 0.44338171793345726 , RMSE train = 0.9416811381854462
iter = 270 , loss = 0.44338169902492225 , RMSE train = 0.9416811381854462
iter = 280 , loss = 0.44338169035318437 , RMSE train = 0.9416811381854462
iter = 290 , loss = 0.44338168637617814 , RMSE train = 0.9416811381854462
iter = 300 , loss = 0.4433816845522474 , RMSE train = 0.9416811381854462
iter = 310 , loss = 0.44338168371575415 , RMSE train = 0.9416811381854462
iter = 320 , loss = 0.44338168333211875 , RMSE train = 0.9416811381854462
iter = 330 , loss = 0.44338168315617366 , RMSE train = 0.9416811381854462
iter = 340 , loss = 0.44338168307548026 , RMSE train = 0.9416811381854462
iter = 350 , loss = 0.4433816830384718 , RMSE train = 0.9416811381854462
iter = 360 , loss = 0.4433816830214985 , RMSE train = 0.9416811381854462
iter = 370 , loss = 0.4433816830137139 , RMSE train = 0.9416811381854462
iter = 380 , loss = 0.4433816830101436 , RMSE train = 0.9416811381854462
iter = 390 , loss = 0.44338168300850606 , RMSE train = 0.9416811381854462
iter = 400 , loss = 0.44338168300775505 , RMSE train = 0.9416811381854462
iter = 410 , loss = 0.44338168300741054 , RMSE train = 0.9416811381854462
iter = 420 , loss = 0.44338168300725256 , RMSE train = 0.9416811381854462
iter = 430 , loss = 0.4433816830071801 , RMSE train = 0.9416811381854462
iter = 440 , loss = 0.44338168300714687 , RMSE train = 0.9416811381854462
iter = 450 , loss = 0.44338168300713166 , RMSE train = 0.9416811381854462
iter = 460 , loss = 0.44338168300712466 , RMSE train = 0.9416811381854462
iter = 470 , loss = 0.44338168300712144 , RMSE train = 0.9416811381854462
iter = 480 , loss = 0.44338168300711994 , RMSE train = 0.9416811381854462
iter = 490 , loss = 0.4433816830071193 , RMSE train = 0.9416811381854462
iter = 500 , loss = 0.443381683007119 , RMSE train = 0.9416811381854462

Item-based MF, RMSE = 1.83827243343475

################################################################################

edit totalLike: tlike/2 + 1

################################################################################
user-based = 1 ( ~ user-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 1

iter = 10 , loss = 60.37516330337366 , RMSE train = 3.5899632389051295
iter = 20 , loss = 50.71596854053976 , RMSE train = 3.2705923553410563
iter = 30 , loss = 43.4901977718052 , RMSE train = 2.94053675188646
iter = 40 , loss = 37.84669704557025 , RMSE train = 2.62135923070337
iter = 50 , loss = 33.29387884088299 , RMSE train = 2.3247461540009176
iter = 60 , loss = 29.525683144404763 , RMSE train = 2.065561849552467
iter = 70 , loss = 26.34254605302927 , RMSE train = 1.8487906898580957
iter = 80 , loss = 23.609809215552694 , RMSE train = 1.6707717686156385
iter = 90 , loss = 21.233895122745526 , RMSE train = 1.5304916065631504
iter = 100 , loss = 19.147940378505403 , RMSE train = 1.423660853566171
iter = 110 , loss = 17.302839368187136 , RMSE train = 1.3454702778419005
iter = 120 , loss = 15.661529319882524 , RMSE train = 1.2905304738221492
iter = 130 , loss = 14.195278358024163 , RMSE train = 1.2528680464429027
iter = 140 , loss = 12.881238492013463 , RMSE train = 1.2274179644911234
iter = 150 , loss = 11.700810387372858 , RMSE train = 1.210460210747274
iter = 160 , loss = 10.638535710528751 , RMSE train = 1.199298688017088
iter = 170 , loss = 9.681335976307047 , RMSE train = 1.192033058046108
iter = 180 , loss = 8.817981145668467 , RMSE train = 1.1873634095578183
iter = 190 , loss = 8.03871197328728 , RMSE train = 1.184410502112639
iter = 200 , loss = 7.334966239564796 , RMSE train = 1.1825828296349583
iter = 210 , loss = 6.699175921449435 , RMSE train = 1.181486058338862
iter = 220 , loss = 6.124613393296198 , RMSE train = 1.1808589871989132
iter = 230 , loss = 5.605271993363861 , RMSE train = 1.1805293653630191
iter = 240 , loss = 5.1357710720504475 , RMSE train = 1.180384448041337
iter = 250 , loss = 4.711278807786519 , RMSE train = 1.180350908778538
iter = 260 , loss = 4.3274481879990265 , RMSE train = 1.1803816836833598
iter = 270 , loss = 3.9803629656606794 , RMSE train = 1.18044692848809
iter = 280 , loss = 3.6664913524409584 , RMSE train = 1.1805280414295467
iter = 290 , loss = 3.382645852507506 , RMSE train = 1.1806136843778587
iter = 300 , loss = 3.1259480790207412 , RMSE train = 1.180697266751664
iter = 310 , loss = 2.893797696164844 , RMSE train = 1.1807751909536301
iter = 320 , loss = 2.6838448382192057 , RMSE train = 1.1808457379679533
iter = 330 , loss = 2.49396550369366 , RMSE train = 1.180908337857149
iter = 340 , loss = 2.3222395269462757 , RMSE train = 1.1809630969923117
iter = 350 , loss = 2.16693080536763 , RMSE train = 1.1810104962284957
iter = 360 , loss = 2.0264695161371478 , RMSE train = 1.1810512012559065
iter = 370 , loss = 1.899436098777676 , RMSE train = 1.1810859460987113
iter = 380 , loss = 1.7845468123416237 , RMSE train = 1.1811154639412464
iter = 390 , loss = 1.6806407018240903 , RMSE train = 1.1811404482526344
iter = 400 , loss = 1.5866678292081609 , RMSE train = 1.1811615330255514
iter = 410 , loss = 1.5016786417031849 , RMSE train = 1.1811792848231606
iter = 420 , loss = 1.4248143641410196 , RMSE train = 1.1811942018966857
iter = 430 , loss = 1.3552983147797395 , RMSE train = 1.1812067173319434
iter = 440 , loss = 1.2924280543781694 , RMSE train = 1.1812172042983806
iter = 450 , loss = 1.2355682876730096 , RMSE train = 1.1812259822040347
iter = 460 , loss = 1.1841444445517268 , RMSE train = 1.1812333230340373
iter = 470 , loss = 1.1376368754488144 , RMSE train = 1.1812394574557592
iter = 480 , loss = 1.0955756019381686 , RMSE train = 1.1812445804680693
iter = 490 , loss = 1.0575355692574715 , RMSE train = 1.1812488564927441
iter = 500 , loss = 1.023132352671456 , RMSE train = 1.1812524238806854

User-based MF, aMSE = 1.2518130567800576

################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 0


iter = 10 , loss = 10.834132725748088 , RMSE train = 1.132287140085857
iter = 20 , loss = 5.125249209101849 , RMSE train = 0.9518366657781745
iter = 30 , loss = 2.5865357995505294 , RMSE train = 0.942327859447374
iter = 40 , loss = 1.4259768602158784 , RMSE train = 0.9417447701880329
iter = 50 , loss = 0.8939673576660205 , RMSE train = 0.9416899721296559
iter = 60 , loss = 0.6500122930250313 , RMSE train = 0.9416825102351296
iter = 70 , loss = 0.538139813483081 , RMSE train = 0.9416813452251186
iter = 80 , loss = 0.486836758665638 , RMSE train = 0.9416811654544648
iter = 90 , loss = 0.46330978676933393 , RMSE train = 0.9416811405248384
iter = 100 , loss = 0.45252055528229324 , RMSE train = 0.9416811379615468
iter = 110 , loss = 0.44757270859611215 , RMSE train = 0.9416811379869947
iter = 120 , loss = 0.4453036638953319 , RMSE train = 0.941681138111652
iter = 130 , loss = 0.44426309481631376 , RMSE train = 0.941681138163124
iter = 140 , loss = 0.4437858954915377 , RMSE train = 0.9416811381793146
iter = 150 , loss = 0.44356705394745366 , RMSE train = 0.9416811381838459
iter = 160 , loss = 0.4434666939183733 , RMSE train = 0.9416811381850418
iter = 170 , loss = 0.44342066901771604 , RMSE train = 0.9416811381853523
iter = 180 , loss = 0.44339956204099396 , RMSE train = 0.9416811381854211
iter = 190 , loss = 0.4433898823763726 , RMSE train = 0.9416811381854399
iter = 200 , loss = 0.4433854432683127 , RMSE train = 0.9416811381854445
iter = 210 , loss = 0.4433834074816115 , RMSE train = 0.9416811381854451
iter = 220 , loss = 0.4433824738619262 , RMSE train = 0.9416811381854457
iter = 230 , loss = 0.4433820456991328 , RMSE train = 0.9416811381854459
iter = 240 , loss = 0.4433818493409187 , RMSE train = 0.9416811381854462
iter = 250 , loss = 0.4433817592895174 , RMSE train = 0.9416811381854462
iter = 260 , loss = 0.4433817179911235 , RMSE train = 0.9416811381854462
iter = 270 , loss = 0.44338169905124597 , RMSE train = 0.9416811381854462
iter = 280 , loss = 0.4433816903651919 , RMSE train = 0.9416811381854462
iter = 290 , loss = 0.443381686381651 , RMSE train = 0.9416811381854462
iter = 300 , loss = 0.44338168455473964 , RMSE train = 0.9416811381854462
iter = 310 , loss = 0.44338168371688796 , RMSE train = 0.9416811381854462
iter = 320 , loss = 0.443381683332634 , RMSE train = 0.9416811381854462
iter = 330 , loss = 0.4433816831564076 , RMSE train = 0.9416811381854462
iter = 340 , loss = 0.4433816830755863 , RMSE train = 0.9416811381854462
iter = 350 , loss = 0.44338168303851977 , RMSE train = 0.9416811381854462
iter = 360 , loss = 0.44338168302152015 , RMSE train = 0.9416811381854462
iter = 370 , loss = 0.44338168301372366 , RMSE train = 0.9416811381854462
iter = 380 , loss = 0.44338168301014796 , RMSE train = 0.9416811381854462
iter = 390 , loss = 0.44338168300850805 , RMSE train = 0.9416811381854462
iter = 400 , loss = 0.44338168300775593 , RMSE train = 0.9416811381854462
iter = 410 , loss = 0.443381683007411 , RMSE train = 0.9416811381854462
iter = 420 , loss = 0.4433816830072528 , RMSE train = 0.9416811381854462
iter = 430 , loss = 0.44338168300718017 , RMSE train = 0.9416811381854462
iter = 440 , loss = 0.4433816830071469 , RMSE train = 0.9416811381854462
iter = 450 , loss = 0.44338168300713166 , RMSE train = 0.9416811381854462
iter = 460 , loss = 0.44338168300712466 , RMSE train = 0.9416811381854462
iter = 470 , loss = 0.44338168300712144 , RMSE train = 0.9416811381854462
iter = 480 , loss = 0.44338168300711994 , RMSE train = 0.9416811381854462
iter = 490 , loss = 0.4433816830071193 , RMSE train = 0.9416811381854462
iter = 500 , loss = 0.443381683007119 , RMSE train = 0.9416811381854462

User-based MF, RMSE = 1.83827243343475

################################################################################

edit totalLike: tlike/3 + 1

################################################################################
user-based = 1 ( ~ user-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 1

iter = 10 , loss = 62.68096678598491 , RMSE train = 3.7459357260554187
iter = 20 , loss = 52.276638310120234 , RMSE train = 3.4269589009296273
iter = 30 , loss = 44.566905678159586 , RMSE train = 3.097330775256239
iter = 40 , loss = 38.60135846374074 , RMSE train = 2.757470072495687
iter = 50 , loss = 33.83128095670444 , RMSE train = 2.441698384942826
iter = 60 , loss = 29.91489743202923 , RMSE train = 2.166471367656769
iter = 70 , loss = 26.629589294746133 , RMSE train = 1.9364458497223611
iter = 80 , loss = 23.825589957831355 , RMSE train = 1.7460611792437986
iter = 90 , loss = 21.39933127828518 , RMSE train = 1.5931009388591284
iter = 100 , loss = 19.27729893077475 , RMSE train = 1.4736620263010487
iter = 110 , loss = 17.40593382909835 , RMSE train = 1.3845072204151192
iter = 120 , loss = 15.745174334054218 , RMSE train = 1.3204854252291485
iter = 130 , loss = 14.26425738348879 , RMSE train = 1.2755288053698282
iter = 140 , loss = 12.938950471570642 , RMSE train = 1.2445894019423684
iter = 150 , loss = 11.749703809071388 , RMSE train = 1.2235243528020066
iter = 160 , loss = 10.680401286250728 , RMSE train = 1.2092815649521163
iter = 170 , loss = 9.71750495693775 , RMSE train = 1.199708510609926
iter = 180 , loss = 8.849460428685246 , RMSE train = 1.1933037830623807
iter = 190 , loss = 8.066276717018269 , RMSE train = 1.189038443857308
iter = 200 , loss = 7.359223798863481 , RMSE train = 1.1862116048817968
iter = 210 , loss = 6.720610345636944 , RMSE train = 1.1843483178875251
iter = 220 , loss = 6.143616686298175 , RMSE train = 1.1831287574639664
iter = 230 , loss = 5.622166308875404 , RMSE train = 1.182337765170218
iter = 240 , loss = 5.150824661873278 , RMSE train = 1.1818312980912813
iter = 250 , loss = 4.724717633874193 , RMSE train = 1.181512770460236
iter = 260 , loss = 4.339464499078671 , RMSE train = 1.1813176642674004
iter = 270 , loss = 3.991121728617027 , RMSE train = 1.181202975603635
iter = 280 , loss = 3.6761351511457563 , RMSE train = 1.1811401175495806
iter = 290 , loss = 3.391298678605999 , RMSE train = 1.1811101420796493
iter = 300 , loss = 3.133718311075576 , RMSE train = 1.1811005803728651
iter = 310 , loss = 2.900780475931403 , RMSE train = 1.18110327278092
iter = 320 , loss = 2.690123992565865 , RMSE train = 1.1811129194205032
iter = 330 , loss = 2.499615118981831 , RMSE train = 1.1811261272731461
iter = 340 , loss = 2.327325253622231 , RMSE train = 1.1811407645496337
iter = 350 , loss = 2.1715109500966787 , RMSE train = 1.1811555289785798
iter = 360 , loss = 2.030595964327356 , RMSE train = 1.1811696596132364
iter = 370 , loss = 1.9031550999639055 , RMSE train = 1.181182744896591
iter = 380 , loss = 1.7878996533820963 , RMSE train = 1.18119459525758
iter = 390 , loss = 1.683664287348449 , RMSE train = 1.1812051589354213
iter = 400 , loss = 1.5893951846614236 , RMSE train = 1.181214466726959
iter = 410 , loss = 1.504139351249728 , RMSE train = 1.1812225960509224
iter = 420 , loss = 1.4270349533444728 , RMSE train = 1.1812296478794655
iter = 430 , loss = 1.357302586160828 , RMSE train = 1.1812357322083336
iter = 440 , loss = 1.2942373825348246 , RMSE train = 1.1812409591634485
iter = 450 , loss = 1.2372018795238784 , RMSE train = 1.1812454337993932
iter = 460 , loss = 1.1856195693664378 , RMSE train = 1.1812492532909142
iter = 470 , loss = 1.1389690686012912 , RMSE train = 1.1812525056511542
iter = 480 , loss = 1.0967788457265406 , RMSE train = 1.1812552694024794
iter = 490 , loss = 1.058622453645576 , RMSE train = 1.1812576138203588
iter = 500 , loss = 1.0241142184019383 , RMSE train = 1.1812595995030535

User-based MF, aMSE = 1.251821892431748

################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 0

iter = 10 , loss = 10.748610958795991 , RMSE train = 1.1162703969533596
iter = 20 , loss = 5.092292370686335 , RMSE train = 0.9498415864876897
iter = 30 , loss = 2.5719656227496754 , RMSE train = 0.9419828086744808
iter = 40 , loss = 1.4193739808529902 , RMSE train = 0.9416759338112638
iter = 50 , loss = 0.8909529795796052 , RMSE train = 0.9416757153169751
iter = 60 , loss = 0.6486320204692553 , RMSE train = 0.9416795338458408
iter = 70 , loss = 0.5375069379695829 , RMSE train = 0.9416807229298597
iter = 80 , loss = 0.48654639371881847 , RMSE train = 0.9416810353345562
iter = 90 , loss = 0.46317652657492825 , RMSE train = 0.9416811133226386
iter = 100 , loss = 0.4524593875448465 , RMSE train = 0.9416811322763268
iter = 110 , loss = 0.44754462965287645 , RMSE train = 0.9416811367991301
iter = 120 , loss = 0.4452907736189878 , RMSE train = 0.9416811378635518
iter = 130 , loss = 0.4442571770073677 , RMSE train = 0.9416811381113273
iter = 140 , loss = 0.44378317858701377 , RMSE train = 0.9416811381684934
iter = 150 , loss = 0.4435658065594718 , RMSE train = 0.9416811381815966
iter = 160 , loss = 0.44346612119854073 , RMSE train = 0.9416811381845764
iter = 170 , loss = 0.44342040605361044 , RMSE train = 0.9416811381852468
iter = 180 , loss = 0.4433994412972893 , RMSE train = 0.9416811381854036
iter = 190 , loss = 0.4433898269333749 , RMSE train = 0.9416811381854356
iter = 200 , loss = 0.443385417809191 , RMSE train = 0.9416811381854454
iter = 210 , loss = 0.44338339579051667 , RMSE train = 0.9416811381854445
iter = 220 , loss = 0.4433824684930627 , RMSE train = 0.9416811381854456
iter = 230 , loss = 0.4433820432335164 , RMSE train = 0.9416811381854459
iter = 240 , loss = 0.4433818482085568 , RMSE train = 0.9416811381854462
iter = 250 , loss = 0.44338175876944713 , RMSE train = 0.9416811381854462
iter = 260 , loss = 0.4433817177522564 , RMSE train = 0.9416811381854462
iter = 270 , loss = 0.4433816989415301 , RMSE train = 0.9416811381854462
iter = 280 , loss = 0.44338169031479535 , RMSE train = 0.9416811381854462
iter = 290 , loss = 0.4433816863585009 , RMSE train = 0.9416811381854462
iter = 300 , loss = 0.443381684544105 , RMSE train = 0.9416811381854462
iter = 310 , loss = 0.4433816837120024 , RMSE train = 0.9416811381854462
iter = 320 , loss = 0.44338168333038946 , RMSE train = 0.9416811381854462
iter = 330 , loss = 0.4433816831553763 , RMSE train = 0.9416811381854462
iter = 340 , loss = 0.44338168307511244 , RMSE train = 0.9416811381854462
iter = 350 , loss = 0.44338168303830205 , RMSE train = 0.9416811381854462
iter = 360 , loss = 0.4433816830214201 , RMSE train = 0.9416811381854462
iter = 370 , loss = 0.4433816830136777 , RMSE train = 0.9416811381854462
iter = 380 , loss = 0.4433816830101268 , RMSE train = 0.9416811381854462
iter = 390 , loss = 0.44338168300849834 , RMSE train = 0.9416811381854462
iter = 400 , loss = 0.44338168300775144 , RMSE train = 0.9416811381854462
iter = 410 , loss = 0.44338168300740893 , RMSE train = 0.9416811381854462
iter = 420 , loss = 0.44338168300725184 , RMSE train = 0.9416811381854462
iter = 430 , loss = 0.4433816830071798 , RMSE train = 0.9416811381854462
iter = 440 , loss = 0.4433816830071467 , RMSE train = 0.9416811381854462
iter = 450 , loss = 0.44338168300713154 , RMSE train = 0.9416811381854462
iter = 460 , loss = 0.4433816830071246 , RMSE train = 0.9416811381854462
iter = 470 , loss = 0.44338168300712144 , RMSE train = 0.9416811381854462
iter = 480 , loss = 0.44338168300711994 , RMSE train = 0.9416811381854462
iter = 490 , loss = 0.4433816830071193 , RMSE train = 0.9416811381854462
iter = 500 , loss = 0.443381683007119 , RMSE train = 0.9416811381854462

User-based MF, RMSE = 1.83827243343475

