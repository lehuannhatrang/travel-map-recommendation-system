
################################################################################
user-based = 1 ( ~ user-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 1

iter = 10 , loss = 11.004642183067457 , RMSE train = 1.286331643640281
iter = 20 , loss = 5.390785571229873 , RMSE train = 1.2048601786065654
iter = 30 , loss = 2.8644914979447607 , RMSE train = 1.2042517760801141
iter = 40 , loss = 1.707469233520075 , RMSE train = 1.2051497660437118
iter = 50 , loss = 1.176706547277151 , RMSE train = 1.2054659440296926
iter = 60 , loss = 0.9331983671970709 , RMSE train = 1.2055600633821462
iter = 70 , loss = 0.8214785049463922 , RMSE train = 1.2055872743542773
iter = 80 , loss = 0.7702199089744856 , RMSE train = 1.2055951377947516
iter = 90 , loss = 0.7466993289621421 , RMSE train = 1.2055974313969975
iter = 100 , loss = 0.735904748567909 , RMSE train = 1.2055981093610812
iter = 110 , loss = 0.7309493166225061 , RMSE train = 1.2055983127096845
iter = 120 , loss = 0.7286735152757882 , RMSE train = 1.205598374581076
iter = 130 , loss = 0.7276277086459866 , RMSE train = 1.2055983936539942
iter = 140 , loss = 0.7271466884508367 , RMSE train = 1.2055983996008888
iter = 150 , loss = 0.7269251408373224 , RMSE train = 1.2055984014729788
iter = 160 , loss = 0.7268228919473597 , RMSE train = 1.2055984020669683
iter = 170 , loss = 0.7267755575380135 , RMSE train = 1.2055984022566368
iter = 180 , loss = 0.7267535456333069 , RMSE train = 1.2055984023174882
iter = 190 , loss = 0.726743242184476 , RMSE train = 1.2055984023371011
iter = 200 , loss = 0.726738374724865 , RMSE train = 1.2055984023434512
iter = 210 , loss = 0.7267360466532244 , RMSE train = 1.20559840234552
iter = 220 , loss = 0.7267349154248302 , RMSE train = 1.20559840234619
iter = 230 , loss = 0.7267343552129706 , RMSE train = 1.2055984023464086
iter = 240 , loss = 0.7267340717889663 , RMSE train = 1.205598402346484
iter = 250 , loss = 0.72673392515458 , RMSE train = 1.2055984023465098
iter = 260 , loss = 0.7267338476297702 , RMSE train = 1.2055984023465143
iter = 270 , loss = 0.7267338058409788 , RMSE train = 1.2055984023465154
iter = 280 , loss = 0.7267337829497756 , RMSE train = 1.2055984023465158
iter = 290 , loss = 0.7267337702520735 , RMSE train = 1.2055984023465158
iter = 300 , loss = 0.7267337631429127 , RMSE train = 1.2055984023465158
iter = 310 , loss = 0.7267337591361461 , RMSE train = 1.2055984023465158
iter = 320 , loss = 0.7267337568674442 , RMSE train = 1.2055984023465158
iter = 330 , loss = 0.7267337555787827 , RMSE train = 1.2055984023465158
iter = 340 , loss = 0.7267337548452149 , RMSE train = 1.2055984023465158
iter = 350 , loss = 0.7267337544270152 , RMSE train = 1.2055984023465158
iter = 360 , loss = 0.7267337541883611 , RMSE train = 1.2055984023465158
iter = 370 , loss = 0.7267337540520714 , RMSE train = 1.2055984023465158
iter = 380 , loss = 0.7267337539742001 , RMSE train = 1.2055984023465158
iter = 390 , loss = 0.7267337539296906 , RMSE train = 1.2055984023465158
iter = 400 , loss = 0.7267337539042429 , RMSE train = 1.2055984023465158
iter = 410 , loss = 0.7267337538896902 , RMSE train = 1.2055984023465158
iter = 420 , loss = 0.7267337538813665 , RMSE train = 1.2055984023465158
iter = 430 , loss = 0.7267337538766049 , RMSE train = 1.2055984023465158
iter = 440 , loss = 0.7267337538738806 , RMSE train = 1.2055984023465158
iter = 450 , loss = 0.7267337538723219 , RMSE train = 1.2055984023465158
iter = 460 , loss = 0.7267337538714298 , RMSE train = 1.2055984023465158
iter = 470 , loss = 0.7267337538709193 , RMSE train = 1.2055984023465158
iter = 480 , loss = 0.7267337538706271 , RMSE train = 1.2055984023465158
iter = 490 , loss = 0.7267337538704598 , RMSE train = 1.2055984023465158
iter = 500 , loss = 0.726733753870364 , RMSE train = 1.2055984023465158

Item-based MF, aMSE = 1.1717812136896786

################################################################################

K = 50, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 1

iter = 10 , loss = 23.895768361990594 , RMSE train = 1.5334314055695448
iter = 20 , loss = 11.130059037340263 , RMSE train = 1.2078262152649835
iter = 30 , loss = 5.490469968383581 , RMSE train = 1.200605888314515
iter = 40 , loss = 2.9122193468325266 , RMSE train = 1.2037503318482734
iter = 50 , loss = 1.729577154855178 , RMSE train = 1.2050237511639268
iter = 60 , loss = 1.1869232660361715 , RMSE train = 1.2054266888933547
iter = 70 , loss = 0.9379267368779844 , RMSE train = 1.2055475250944905
iter = 80 , loss = 0.823673295150843 , RMSE train = 1.2055832784629008
iter = 90 , loss = 0.7712433556287112 , RMSE train = 1.2055938685136736
iter = 100 , loss = 0.7471798060316533 , RMSE train = 1.205597028916874
iter = 110 , loss = 0.7361325086544921 , RMSE train = 1.2055979818048206
iter = 120 , loss = 0.731058740358517 , RMSE train = 1.2055982722749439
iter = 130 , loss = 0.7287270406313869 , RMSE train = 1.205598361755061
iter = 140 , loss = 0.7276545011186768 , RMSE train = 1.2055983895819113
iter = 150 , loss = 0.7271604773700804 , RMSE train = 1.2055983983067642
iter = 160 , loss = 0.7269324610602751 , RMSE train = 1.2055984010612733
iter = 170 , loss = 0.7268269026933093 , RMSE train = 1.2055984019358479
iter = 180 , loss = 0.7267778190331337 , RMSE train = 1.2055984022148225
iter = 190 , loss = 0.7267548503411858 , RMSE train = 1.2055984023041484
iter = 200 , loss = 0.726744006680334 , RMSE train = 1.205598402332848
iter = 210 , loss = 0.7267388263910465 , RMSE train = 1.2055984023420994
iter = 220 , loss = 0.7267363140833505 , RMSE train = 1.2055984023450812
iter = 230 , loss = 0.726735073407043 , RMSE train = 1.205598402346048
iter = 240 , loss = 0.726734448044579 , RMSE train = 1.2055984023463686
iter = 250 , loss = 0.7267341259533051 , RMSE train = 1.20559840234647
iter = 260 , loss = 0.7267339565172551 , RMSE train = 1.205598402346507
iter = 270 , loss = 0.726733865659197 , RMSE train = 1.2055984023465134
iter = 280 , loss = 0.7267338161423513 , RMSE train = 1.2055984023465154
iter = 290 , loss = 0.7267337888076753 , RMSE train = 1.2055984023465158
iter = 300 , loss = 0.7267337735717041 , RMSE train = 1.2055984023465158
iter = 310 , loss = 0.7267337650196858 , RMSE train = 1.2055984023465158
iter = 320 , loss = 0.7267337601955661 , RMSE train = 1.2055984023465158
iter = 330 , loss = 0.7267337574649152 , RMSE train = 1.2055984023465158
iter = 340 , loss = 0.7267337559155538 , RMSE train = 1.2055984023465158
iter = 350 , loss = 0.7267337550349902 , RMSE train = 1.2055984023465158
iter = 360 , loss = 0.7267337545339474 , RMSE train = 1.2055984023465158
iter = 370 , loss = 0.7267337542486156 , RMSE train = 1.2055984023465158
iter = 380 , loss = 0.7267337540860271 , RMSE train = 1.2055984023465158
iter = 390 , loss = 0.7267337539933383 , RMSE train = 1.2055984023465158
iter = 400 , loss = 0.7267337539404791 , RMSE train = 1.2055984023465158
iter = 410 , loss = 0.7267337539103256 , RMSE train = 1.2055984023465158
iter = 420 , loss = 0.7267337538931203 , RMSE train = 1.2055984023465158
iter = 430 , loss = 0.7267337538833012 , RMSE train = 1.2055984023465158
iter = 440 , loss = 0.7267337538776963 , RMSE train = 1.2055984023465158
iter = 450 , loss = 0.7267337538744965 , RMSE train = 1.2055984023465158
iter = 460 , loss = 0.7267337538726694 , RMSE train = 1.2055984023465158
iter = 470 , loss = 0.726733753871626 , RMSE train = 1.2055984023465158
iter = 480 , loss = 0.72673375387103 , RMSE train = 1.2055984023465158
iter = 490 , loss = 0.7267337538706896 , RMSE train = 1.2055984023465158
iter = 500 , loss = 0.7267337538704951 , RMSE train = 1.2055984023465158

Item-based MF, aMSE = 1.1717812136896786

################################################################################

K = 50, lam = .1, learning_rate = 0.1, max_iter = 500, user_based = 1

iter = 10 , loss = 57.770624683932915 , RMSE train = 3.4305686395646586
iter = 20 , loss = 48.24762246432053 , RMSE train = 2.9960086686948086
iter = 30 , loss = 41.57392409582948 , RMSE train = 2.6174902949355134
iter = 40 , loss = 36.45061977464714 , RMSE train = 2.2936700646380572
iter = 50 , loss = 32.30520626717744 , RMSE train = 2.026231124801542
iter = 60 , loss = 28.835390440569203 , RMSE train = 1.808723419712256
iter = 70 , loss = 25.86401433583815 , RMSE train = 1.6348293927904878
iter = 80 , loss = 23.27914675711383 , RMSE train = 1.5013675493557088
iter = 90 , loss = 21.005658946621278 , RMSE train = 1.4031632840516437
iter = 100 , loss = 18.990457913114362 , RMSE train = 1.333696716623624
iter = 110 , loss = 17.194299393556957 , RMSE train = 1.2856851055840615
iter = 120 , loss = 15.587018269359032 , RMSE train = 1.2533583397174801
iter = 130 , loss = 14.1446373070622 , RMSE train = 1.2320783700795248
iter = 140 , loss = 12.847554607479157 , RMSE train = 1.2183571541143796
iter = 150 , loss = 11.679372645250636 , RMSE train = 1.209709927771508
iter = 160 , loss = 10.626120081212546 , RMSE train = 1.2044443361794555
iter = 170 , loss = 9.67572002248642 , RMSE train = 1.2013976649825726
iter = 180 , loss = 8.817616353971179 , RMSE train = 1.199785585824109
iter = 190 , loss = 8.042503565279041 , RMSE train = 1.1990878423696567
iter = 200 , loss = 7.342125724913138 , RMSE train = 1.1989586031537969
iter = 210 , loss = 6.709122619567121 , RMSE train = 1.199170096356459
iter = 220 , loss = 6.136908772768055 , RMSE train = 1.1995734499020754
iter = 230 , loss = 5.619575920620704 , RMSE train = 1.200073209310956
iter = 240 , loss = 5.151812636855644 , RMSE train = 1.2006086947850931
iter = 250 , loss = 4.728836817660638 , RMSE train = 1.2011422246307655
iter = 260 , loss = 4.3463380593273495 , RMSE train = 1.2016520854633435
iter = 270 , loss = 4.000427837885379 , RMSE train = 1.2021261663703038
iter = 280 , loss = 3.687595986830426 , RMSE train = 1.2025587149422905
iter = 290 , loss = 3.4046723669851287 , RMSE train = 1.2029480333139817
iter = 300 , loss = 3.1487928959222726 , RMSE train = 1.2032949205146477
iter = 310 , loss = 2.917369295029687 , RMSE train = 1.2036016344462779
iter = 320 , loss = 2.7080620475076276 , RMSE train = 1.203871213415035
iter = 330 , loss = 2.5187561583076548 , RMSE train = 1.2041070387265451
iter = 340 , loss = 2.347539379119769 , RMSE train = 1.2043125585582222
iter = 350 , loss = 2.1926826158948316 , RMSE train = 1.2044911193147543
iter = 360 , loss = 2.0526222783492853 , RMSE train = 1.204645868168687
iter = 370 , loss = 1.925944364010169 , RMSE train = 1.2047797022886992
iter = 380 , loss = 1.8113700960586996 , RMSE train = 1.2048952482378075
iter = 390 , loss = 1.7077429561879327 , RMSE train = 1.2049948604278282
iter = 400 , loss = 1.614016972067477 , RMSE train = 1.2050806311825368
iter = 410 , loss = 1.529246134625562 , RMSE train = 1.20515440745287
iter = 420 , loss = 1.452574833796272 , RMSE train = 1.205217810917741
iter = 430 , loss = 1.3832292130675923 , RMSE train = 1.2052722593533252
iter = 440 , loss = 1.320509353412123 , RMSE train = 1.2053189879295625
iter = 450 , loss = 1.263782206231046 , RMSE train = 1.2053590696179912
iter = 460 , loss = 1.2124752029702017 , RMSE train = 1.2053934342449895
iter = 470 , loss = 1.1660704762238017 , RMSE train = 1.2054228859575173
iter = 480 , loss = 1.1240996335391769 , RMSE train = 1.2054481190196624
iter = 490 , loss = 1.0861390308714136 , RMSE train = 1.205469731954716
iter = 500 , loss = 1.051805497787445 , RMSE train = 1.2054882401059668

Item-based MF, aMSE = 1.1717843006778277


################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 10, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 0

iter = 10 , loss = 10.734770296977398 , RMSE train = 1.0530569231977092
iter = 20 , loss = 5.113854393026885 , RMSE train = 0.9466218336759151
iter = 30 , loss = 2.583948580230446 , RMSE train = 0.9427415672504873
iter = 40 , loss = 1.4256853249262267 , RMSE train = 0.9428407477904791
iter = 50 , loss = 0.8945528850290849 , RMSE train = 0.9429238635961961
iter = 60 , loss = 0.6509586314505381 , RMSE train = 0.942948855412342
iter = 70 , loss = 0.5392370519674542 , RMSE train = 0.9429554720309734
iter = 80 , loss = 0.48799706645738566 , RMSE train = 0.9429571478667143
iter = 90 , loss = 0.4644961358514831 , RMSE train = 0.9429575620899169
iter = 100 , loss = 0.45371740783664033 , RMSE train = 0.9429576628106067
iter = 110 , loss = 0.44877363984979385 , RMSE train = 0.9429576870122618
iter = 120 , loss = 0.44650608347190446 , RMSE train = 0.942957692776177
iter = 130 , loss = 0.4454659988383482 , RMSE train = 0.9429576941397417
iter = 140 , loss = 0.4449889191709071 , RMSE train = 0.942957694460669
iter = 150 , loss = 0.4447700795883424 , RMSE train = 0.9429576945359248
iter = 160 , loss = 0.4446696932100938 , RMSE train = 0.9429576945535127
iter = 170 , loss = 0.44462364222027323 , RMSE train = 0.9429576945576172
iter = 180 , loss = 0.4446025160905999 , RMSE train = 0.9429576945585773
iter = 190 , loss = 0.44459282395625804 , RMSE train = 0.9429576945587925
iter = 200 , loss = 0.44458837724033046 , RMSE train = 0.9429576945588575
iter = 210 , loss = 0.44458633699648953 , RMSE train = 0.9429576945588698
iter = 220 , loss = 0.4445854008365386 , RMSE train = 0.9429576945588725
iter = 230 , loss = 0.44458497125434554 , RMSE train = 0.9429576945588727
iter = 240 , loss = 0.4445847741146555 , RMSE train = 0.9429576945588727
iter = 250 , loss = 0.4445846836378435 , RMSE train = 0.9429576945588727
iter = 260 , loss = 0.4445846421099099 , RMSE train = 0.9429576945588727
iter = 270 , loss = 0.44458462304704466 , RMSE train = 0.9429576945588727
iter = 280 , loss = 0.4445846142954621 , RMSE train = 0.9429576945588727
iter = 290 , loss = 0.4445846102771642 , RMSE train = 0.9429576945588727
iter = 300 , loss = 0.44458460843188424 , RMSE train = 0.9429576945588727
iter = 310 , loss = 0.44458460758435325 , RMSE train = 0.9429576945588727
iter = 320 , loss = 0.44458460719501075 , RMSE train = 0.9429576945588727
iter = 330 , loss = 0.44458460701611413 , RMSE train = 0.9429576945588727
iter = 340 , loss = 0.4445846069338938 , RMSE train = 0.9429576945588727
iter = 350 , loss = 0.444584606896095 , RMSE train = 0.9429576945588727
iter = 360 , loss = 0.4445846068787125 , RMSE train = 0.9429576945588727
iter = 370 , loss = 0.4445846068707158 , RMSE train = 0.9429576945588727
iter = 380 , loss = 0.4445846068670356 , RMSE train = 0.9429576945588727
iter = 390 , loss = 0.44458460686534107 , RMSE train = 0.9429576945588727
iter = 400 , loss = 0.44458460686456047 , RMSE train = 0.9429576945588727
iter = 410 , loss = 0.44458460686420065 , RMSE train = 0.9429576945588727
iter = 420 , loss = 0.44458460686403467 , RMSE train = 0.9429576945588727
iter = 430 , loss = 0.444584606863958 , RMSE train = 0.9429576945588727
iter = 440 , loss = 0.44458460686392265 , RMSE train = 0.9429576945588727
iter = 450 , loss = 0.4445846068639063 , RMSE train = 0.9429576945588727
iter = 460 , loss = 0.44458460686389867 , RMSE train = 0.9429576945588727
iter = 470 , loss = 0.44458460686389517 , RMSE train = 0.9429576945588727
iter = 480 , loss = 0.44458460686389356 , RMSE train = 0.9429576945588727
iter = 490 , loss = 0.4445846068638928 , RMSE train = 0.9429576945588727
iter = 500 , loss = 0.44458460686389245 , RMSE train = 0.9429576945588727

User-based MF, RMSE = 3.782003191319533

################################################################################

K = 50, lam = .1, learning_rate = 0.75, max_iter = 500, user_based = 0

iter = 10 , loss = 23.662844848040745 , RMSE train = 1.3508090528607015
iter = 20 , loss = 10.867588786598922 , RMSE train = 0.9576512021827828
iter = 30 , loss = 5.216324703050841 , RMSE train = 0.9414040274337012
iter = 40 , loss = 2.6329559012212678 , RMSE train = 0.942275083089652
iter = 50 , loss = 1.4483293213546962 , RMSE train = 0.9427656723328545
iter = 60 , loss = 0.9049690153782042 , RMSE train = 0.942908028274154
iter = 70 , loss = 0.6557456019965437 , RMSE train = 0.9429452682746139
iter = 80 , loss = 0.5414364982129256 , RMSE train = 0.9429546453980242
iter = 90 , loss = 0.48900763803539177 , RMSE train = 0.9429569562852862
iter = 100 , loss = 0.4649605160017517 , RMSE train = 0.9429575175366233
iter = 110 , loss = 0.4539308427520778 , RMSE train = 0.9429576524188589
iter = 120 , loss = 0.4488717620090235 , RMSE train = 0.9429576845815869
iter = 130 , loss = 0.4465512067353163 , RMSE train = 0.9429576922060678
iter = 140 , loss = 0.4454867569446906 , RMSE train = 0.9429576940056631
iter = 150 , loss = 0.4449984724493565 , RMSE train = 0.9429576944290633
iter = 160 , loss = 0.4447744782524037 , RMSE train = 0.9429576945284485
iter = 170 , loss = 0.4446717195962765 , RMSE train = 0.9429576945517378
iter = 180 , loss = 0.44462457631279184 , RMSE train = 0.9429576945571889
iter = 190 , loss = 0.4446029469755729 , RMSE train = 0.942957694558475
iter = 200 , loss = 0.4445930228764773 , RMSE train = 0.9429576945587749
iter = 210 , loss = 0.44458846915614825 , RMSE train = 0.9429576945588517
iter = 220 , loss = 0.4445863795121395 , RMSE train = 0.942957694558867
iter = 230 , loss = 0.44458542052511807 , RMSE train = 0.942957694558871
iter = 240 , loss = 0.4445849803839794 , RMSE train = 0.9429576945588726
iter = 250 , loss = 0.4445847783543945 , RMSE train = 0.9429576945588727
iter = 260 , loss = 0.4445846856100491 , RMSE train = 0.9429576945588727
iter = 270 , loss = 0.444584643029047 , RMSE train = 0.9429576945588727
iter = 280 , loss = 0.4445846234763023 , RMSE train = 0.9429576945588727
iter = 290 , loss = 0.444584614496402 , RMSE train = 0.9429576945588727
iter = 300 , loss = 0.4445846103714685 , RMSE train = 0.9429576945588727
iter = 310 , loss = 0.44458460847626796 , RMSE train = 0.9429576945588727
iter = 320 , loss = 0.4445846076053067 , RMSE train = 0.9429576945588727
iter = 330 , loss = 0.444584607204936 , RMSE train = 0.9429576945588727
iter = 340 , loss = 0.4445846070208324 , RMSE train = 0.9429576945588727
iter = 350 , loss = 0.4445846069361454 , RMSE train = 0.9429576945588727
iter = 360 , loss = 0.44458460689717383 , RMSE train = 0.9429576945588727
iter = 370 , loss = 0.44458460687923157 , RMSE train = 0.9429576945588727
iter = 380 , loss = 0.4445846068709667 , RMSE train = 0.9429576945588727
iter = 390 , loss = 0.4445846068671574 , RMSE train = 0.9429576945588727
iter = 400 , loss = 0.44458460686540047 , RMSE train = 0.9429576945588727
iter = 410 , loss = 0.44458460686458956 , RMSE train = 0.9429576945588727
iter = 420 , loss = 0.4445846068642149 , RMSE train = 0.9429576945588727
iter = 430 , loss = 0.4445846068640417 , RMSE train = 0.9429576945588727
iter = 440 , loss = 0.4445846068639615 , RMSE train = 0.9429576945588727
iter = 450 , loss = 0.44458460686392437 , RMSE train = 0.9429576945588727
iter = 460 , loss = 0.4445846068639071 , RMSE train = 0.9429576945588727
iter = 470 , loss = 0.4445846068638991 , RMSE train = 0.9429576945588727
iter = 480 , loss = 0.4445846068638954 , RMSE train = 0.9429576945588727
iter = 490 , loss = 0.44458460686389367 , RMSE train = 0.9429576945588727
iter = 500 , loss = 0.44458460686389284 , RMSE train = 0.9429576945588727

User-based MF, RMSE = 3.782003191319533


