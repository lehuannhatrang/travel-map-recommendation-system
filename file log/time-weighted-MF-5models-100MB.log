
################################################################################
user-based = 1 ( ~ user-based)
################################################################################


K = 100, lam = .5, learning_rate = 0.75, max_iter = 300, user_based = 1

iter = 10 , loss = 5.678282462306284 , RMSE train = 1.4731778214765106
iter = 20 , loss = 1.1269457106935656 , RMSE train = 1.4732050441153823
iter = 30 , loss = 1.0855466087854844 , RMSE train = 1.4732050489130417
iter = 40 , loss = 1.0851700155325177 , RMSE train = 1.4732050489136197
iter = 50 , loss = 1.0851665895285663 , RMSE train = 1.4732050489136197
iter = 60 , loss = 1.0851665583585057 , RMSE train = 1.4732050489136197
iter = 70 , loss = 1.0851665580748948 , RMSE train = 1.4732050489136197
iter = 80 , loss = 1.0851665580723142 , RMSE train = 1.4732050489136197
iter = 90 , loss = 1.0851665580722907 , RMSE train = 1.4732050489136197
iter = 100 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 110 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 120 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 130 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 140 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 150 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 160 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 170 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 180 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 190 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 200 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 210 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 220 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 230 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 240 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 250 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 260 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 270 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 280 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 290 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197
iter = 300 , loss = 1.0851665580722905 , RMSE train = 1.4732050489136197

User-based MF, RMSE = 1.559850018072879


iter = 10 , loss = 5.442664847652945 , RMSE train = 1.304302110554037
iter = 20 , loss = 0.8924028292212857 , RMSE train = 1.3043269152313306
iter = 30 , loss = 0.8510142973579745 , RMSE train = 1.3043269195446323
iter = 40 , loss = 0.8506378128146831 , RMSE train = 1.304326919545192
iter = 50 , loss = 0.8506343879686799 , RMSE train = 1.304326919545192
iter = 60 , loss = 0.8506343568112009 , RMSE train = 1.304326919545192
iter = 70 , loss = 0.850634356527728 , RMSE train = 1.304326919545192
iter = 80 , loss = 0.8506343565251487 , RMSE train = 1.304326919545192
iter = 90 , loss = 0.8506343565251253 , RMSE train = 1.304326919545192
iter = 100 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 110 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 120 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 130 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 140 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 150 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 160 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 170 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 180 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 190 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 200 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 210 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 220 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 230 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 240 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 250 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 260 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 270 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 280 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 290 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192
iter = 300 , loss = 0.8506343565251251 , RMSE train = 1.304326919545192

User-based MF, RMSE = 1.4290202883854148


iter = 10 , loss = 5.910908408347865 , RMSE train = 1.6256895510686984
iter = 20 , loss = 1.3632291314254472 , RMSE train = 1.62571980562845
iter = 30 , loss = 1.3218622213633506 , RMSE train = 1.6257198108842983
iter = 40 , loss = 1.3214859068329405 , RMSE train = 1.625719810884994
iter = 50 , loss = 1.3214824831886787 , RMSE train = 1.6257198108849942
iter = 60 , loss = 1.321482452038031 , RMSE train = 1.6257198108849942
iter = 70 , loss = 1.3214824517545738 , RMSE train = 1.6257198108849942
iter = 80 , loss = 1.3214824517519943 , RMSE train = 1.6257198108849942
iter = 90 , loss = 1.3214824517519708 , RMSE train = 1.6257198108849942
iter = 100 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 110 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 120 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 130 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 140 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 150 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 160 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 170 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 180 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 190 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 200 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 210 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 220 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 230 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 240 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 250 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 260 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 270 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 280 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 290 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942
iter = 300 , loss = 1.3214824517519705 , RMSE train = 1.6257198108849942

User-based MF, RMSE = 1.7651253608863118


iter = 10 , loss = 5.867058780045778 , RMSE train = 1.5958537343806145
iter = 20 , loss = 1.3152126447744334 , RMSE train = 1.595887117190626
iter = 30 , loss = 1.2738079686788328 , RMSE train = 1.5958871227165057
iter = 40 , loss = 1.2734313124252232 , RMSE train = 1.5958871227171976
iter = 50 , loss = 1.2734278856921286 , RMSE train = 1.5958871227171976
iter = 60 , loss = 1.2734278545136017 , RMSE train = 1.5958871227171976
iter = 70 , loss = 1.2734278542298934 , RMSE train = 1.5958871227171976
iter = 80 , loss = 1.2734278542273116 , RMSE train = 1.5958871227171976
iter = 90 , loss = 1.273427854227288 , RMSE train = 1.5958871227171976
iter = 100 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 110 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 120 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 130 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 140 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 150 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 160 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 170 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 180 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 190 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 200 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 210 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 220 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 230 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 240 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 250 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 260 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 270 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 280 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 290 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976
iter = 300 , loss = 1.2734278542272879 , RMSE train = 1.5958871227171976

User-based MF, RMSE = 1.7031409065214465


iter = 10 , loss = 5.652981200472186 , RMSE train = 1.4567192436960905
iter = 20 , loss = 1.1028304058060068 , RMSE train = 1.4567510487089292
iter = 30 , loss = 1.0614417726041 , RMSE train = 1.4567510538380994
iter = 40 , loss = 1.0610652730369265 , RMSE train = 1.4567510538387454
iter = 50 , loss = 1.0610618478786542 , RMSE train = 1.4567510538387454
iter = 60 , loss = 1.0610618167162915 , RMSE train = 1.4567510538387454
iter = 70 , loss = 1.0610618164327512 , RMSE train = 1.4567510538387454
iter = 80 , loss = 1.0610618164301713 , RMSE train = 1.4567510538387454
iter = 90 , loss = 1.0610618164301477 , RMSE train = 1.4567510538387454
iter = 100 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 110 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 120 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 130 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 140 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 150 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 160 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 170 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 180 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 190 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 200 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 210 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 220 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 230 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 240 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 250 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 260 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 270 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 280 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 290 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454
iter = 300 , loss = 1.0610618164301475 , RMSE train = 1.4567510538387454

User-based MF, RMSE = 1.5982716314787406

User-based MF-5models, RMSE = 1.3584726568765553

################################################################################

K = 100, lam = .1, learning_rate = 0.1, max_iter = 200, user_based = 1

iter = 10 , loss = 309.45993441706594 , RMSE train = 3.0939201520942006
iter = 20 , loss = 182.84745481612046 , RMSE train = 1.8891223588629538
iter = 30 , loss = 109.55130900338415 , RMSE train = 1.5310556191421558
iter = 40 , loss = 65.98206016285182 , RMSE train = 1.4788499159632287
iter = 50 , loss = 39.93588066605637 , RMSE train = 1.4730925884237125
iter = 60 , loss = 24.346092870622325 , RMSE train = 1.4728373839836284
iter = 70 , loss = 15.012437785601417 , RMSE train = 1.4730123724998636
iter = 80 , loss = 9.42403316619261 , RMSE train = 1.473121405296067
iter = 90 , loss = 6.078012319430645 , RMSE train = 1.4731707703188943
iter = 100 , loss = 4.074601832727799 , RMSE train = 1.473191340420818
iter = 110 , loss = 2.875072117060074 , RMSE train = 1.4731996406436239
iter = 120 , loss = 2.156861431436414 , RMSE train = 1.473202934914042
iter = 130 , loss = 1.7268374847835113 , RMSE train = 1.4732042284756468
iter = 140 , loss = 1.4693634235988289 , RMSE train = 1.4732047323735153
iter = 150 , loss = 1.3152024319735494 , RMSE train = 1.4732049273973502
iter = 160 , loss = 1.2228994457364482 , RMSE train = 1.47320500246724
iter = 170 , loss = 1.1676335383349257 , RMSE train = 1.473205031228331
iter = 180 , loss = 1.134543353716846 , RMSE train = 1.4732050422023615
iter = 190 , loss = 1.1147307555701895 , RMSE train = 1.4732050463744968
iter = 200 , loss = 1.102868042035584 , RMSE train = 1.4732050479555816

User-based MF, RMSE = 1.5598500181735346


iter = 10 , loss = 309.52571101759776 , RMSE train = 2.9997977711743893
iter = 20 , loss = 182.75723358811913 , RMSE train = 1.754488015168764
iter = 30 , loss = 109.39958166954979 , RMSE train = 1.369485358792875
iter = 40 , loss = 65.79687014391168 , RMSE train = 1.3107399377164242
iter = 50 , loss = 39.73091424375485 , RMSE train = 1.3042462098730272
iter = 60 , loss = 24.12927411967999 , RMSE train = 1.303944340775311
iter = 70 , loss = 14.788511021971061 , RMSE train = 1.3041275485496486
iter = 80 , loss = 9.195847768136668 , RMSE train = 1.3042414498385393
iter = 90 , loss = 5.847277292364847 , RMSE train = 1.3042923278543503
iter = 100 , loss = 3.8423409709449334 , RMSE train = 1.3043132387187961
iter = 110 , loss = 2.641898324570659 , RMSE train = 1.304321573603076
iter = 120 , loss = 1.9231415073304832 , RMSE train = 1.3043248469718305
iter = 130 , loss = 1.4927909042019696 , RMSE train = 1.3043261208385897
iter = 140 , loss = 1.235121492406519 , RMSE train = 1.3043266132680709
iter = 150 , loss = 1.0808436962135834 , RMSE train = 1.3043268025955739
iter = 160 , loss = 0.9884708837681601 , RMSE train = 1.3043268750543189
iter = 170 , loss = 0.9331632429583652 , RMSE train = 1.3043269026751632
iter = 180 , loss = 0.9000481209758848 , RMSE train = 1.3043269131671522
iter = 190 , loss = 0.8802206252983266 , RMSE train = 1.3043269171401926
iter = 200 , loss = 0.8683490141865393 , RMSE train = 1.3043269186404747

User-based MF, RMSE = 1.4290202883588896


iter = 10 , loss = 309.83779706979084 , RMSE train = 3.1544610107863957
iter = 20 , loss = 183.12755679683224 , RMSE train = 2.0097646379859593
iter = 30 , loss = 109.80705641002 , RMSE train = 1.6806450802806594
iter = 40 , loss = 66.22861045772667 , RMSE train = 1.631439340729894
iter = 50 , loss = 40.1779889467919 , RMSE train = 1.625774600934352
iter = 60 , loss = 24.585793739760565 , RMSE train = 1.625425431048187
iter = 70 , loss = 15.250762844779882 , RMSE train = 1.6255533962428002
iter = 80 , loss = 9.661551293472623 , RMSE train = 1.625644963494207
iter = 90 , loss = 6.315050805617492 , RMSE train = 1.6256883848755104
iter = 100 , loss = 4.311353179830544 , RMSE train = 1.6257070069362403
iter = 110 , loss = 3.1116508818027073 , RMSE train = 1.625714683196921
iter = 120 , loss = 2.393336218543987 , RMSE train = 1.6257177816184842
iter = 130 , loss = 1.9632495263239522 , RMSE train = 1.6257190151087344
iter = 140 , loss = 1.7057375543731592 , RMSE train = 1.6257195011306695
iter = 150 , loss = 1.5515536328491824 , RMSE train = 1.6257196910626877
iter = 160 , loss = 1.459236764162113 , RMSE train = 1.6257197647803956
iter = 170 , loss = 1.4039624440421499 , RMSE train = 1.6257197932267928
iter = 180 , loss = 1.3708671567122053 , RMSE train = 1.6257198041491074
iter = 190 , loss = 1.351051460792032 , RMSE train = 1.6257198083246571
iter = 200 , loss = 1.3391868650351741 , RMSE train = 1.6257198099148689

User-based MF, RMSE = 1.7651253610919317


iter = 10 , loss = 309.3632530499631 , RMSE train = 3.148322178888566
iter = 20 , loss = 182.8678150615397 , RMSE train = 1.9877705721327665
iter = 30 , loss = 109.63790718913448 , RMSE train = 1.6508971360524185
iter = 40 , loss = 66.10882230713332 , RMSE train = 1.6015848725013997
iter = 50 , loss = 40.08709341442909 , RMSE train = 1.5959305510298827
iter = 60 , loss = 24.512102771186704 , RMSE train = 1.5955889784505028
iter = 70 , loss = 15.187359089041335 , RMSE train = 1.5957196781151923
iter = 80 , loss = 9.60430525325078 , RMSE train = 1.5958120485806662
iter = 90 , loss = 6.261491812954802 , RMSE train = 1.59585567005115
iter = 100 , loss = 4.260002113098633 , RMSE train = 1.595874329248477
iter = 110 , loss = 3.0616220526431137 , RMSE train = 1.5958820060279346
iter = 120 , loss = 2.344099243468069 , RMSE train = 1.5958850999985146
iter = 130 , loss = 1.9144867815004494 , RMSE train = 1.5958863302239152
iter = 140 , loss = 1.6572588248554136 , RMSE train = 1.59588681447582
iter = 150 , loss = 1.5032450029343618 , RMSE train = 1.5958870035579695
iter = 160 , loss = 1.4110300109101417 , RMSE train = 1.595887076893702
iter = 170 , loss = 1.3558167086087334 , RMSE train = 1.5958871051753807
iter = 180 , loss = 1.3227579681123223 , RMSE train = 1.5958871160286754
iter = 190 , loss = 1.302964162625402 , RMSE train = 1.5958871201759013
iter = 200 , loss = 1.2911126789240848 , RMSE train = 1.5958871217546589

User-based MF, RMSE = 1.7031409066191223


iter = 10 , loss = 309.6137867662614 , RMSE train = 3.0843169973752227
iter = 20 , loss = 182.92172558964722 , RMSE train = 1.8806205531219717
iter = 30 , loss = 109.5841532240157 , RMSE train = 1.5169557330423071
iter = 40 , loss = 65.99143629005698 , RMSE train = 1.4630980000382263
iter = 50 , loss = 39.93160790709411 , RMSE train = 1.4568721199248944
iter = 60 , loss = 24.33378533765526 , RMSE train = 1.45646543340394
iter = 70 , loss = 14.99536847151745 , RMSE train = 1.456587908816109
iter = 80 , loss = 9.404130498626838 , RMSE train = 1.4566781334633558
iter = 90 , loss = 6.0564196613025105 , RMSE train = 1.4567206806483086
iter = 100 , loss = 4.051999675440704 , RMSE train = 1.4567387689836162
iter = 110 , loss = 2.851866412760648 , RMSE train = 1.4567461646158126
iter = 120 , loss = 2.1332946978558223 , RMSE train = 1.4567491290631724
iter = 130 , loss = 1.7030547268132865 , RMSE train = 1.4567503023723274
iter = 140 , loss = 1.445451385364391 , RMSE train = 1.456750762433469
iter = 150 , loss = 1.2912130199643852 , RMSE train = 1.456750941480256
iter = 160 , loss = 1.1988637248070761 , RMSE train = 1.4567510107282489
iter = 170 , loss = 1.143570101390484 , RMSE train = 1.456751037368349
iter = 180 , loss = 1.1104633291737267 , RMSE train = 1.4567510475698096
iter = 190 , loss = 1.090640804039359 , RMSE train = 1.456751051460613
iter = 200 , loss = 1.078772149917736 , RMSE train = 1.4567510529392595

User-based MF, RMSE = 1.5982716313892351

User-based MF-5models, RMSE = 1.3584726569406078

################################################################################
user-based = 0 ( ~ item-based)
################################################################################

K = 100, lam = .5, learning_rate = 0.75, max_iter = 200, user_based = 0

iter = 10 , loss = 5.527688475631078 , RMSE train = 1.3653811011097663
iter = 20 , loss = 0.9739673411095587 , RMSE train = 1.365406408761198
iter = 30 , loss = 0.9325475627142391 , RMSE train = 1.3654064131546724
iter = 40 , loss = 0.9321707954198658 , RMSE train = 1.3654064131551935
iter = 50 , loss = 0.9321673680097305 , RMSE train = 1.3654064131551935
iter = 60 , loss = 0.9321673368289553 , RMSE train = 1.3654064131551935
iter = 70 , loss = 0.9321673365452704 , RMSE train = 1.3654064131551935
iter = 80 , loss = 0.9321673365426891 , RMSE train = 1.3654064131551935
iter = 90 , loss = 0.9321673365426657 , RMSE train = 1.3654064131551935
iter = 100 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935
iter = 110 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935
iter = 120 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935
iter = 130 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935
iter = 140 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935
iter = 150 , loss = 0.9321673365426655 , RMSE train = 1.3654064131551935

User-based MF, RMSE = 3.0481492151186975


iter = 10 , loss = 5.417326831616825 , RMSE train = 1.2845524556907557
iter = 20 , loss = 0.866838273205591 , RMSE train = 1.284576373245091
iter = 30 , loss = 0.8254481827352163 , RMSE train = 1.2845763773447143
iter = 40 , loss = 0.8250716908862039 , RMSE train = 1.2845763773452048
iter = 50 , loss = 0.8250682660590338 , RMSE train = 1.2845763773452048
iter = 60 , loss = 0.8250682349027189 , RMSE train = 1.2845763773452048
iter = 70 , loss = 0.8250682346192676 , RMSE train = 1.2845763773452048
iter = 80 , loss = 0.8250682346166887 , RMSE train = 1.2845763773452048
iter = 90 , loss = 0.8250682346166652 , RMSE train = 1.2845763773452048
iter = 100 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048
iter = 110 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048
iter = 120 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048
iter = 130 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048
iter = 140 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048
iter = 150 , loss = 0.825068234616665 , RMSE train = 1.2845763773452048

User-based MF, RMSE = 3.102131164799738


iter = 10 , loss = 5.790393362766651 , RMSE train = 1.5482575161325287
iter = 20 , loss = 1.2403720993216214 , RMSE train = 1.54829209310368
iter = 30 , loss = 1.198984167280271 , RMSE train = 1.5482920985784263
iter = 40 , loss = 1.1986076679454842 , RMSE train = 1.5482920985791055
iter = 50 , loss = 1.1986042427113826 , RMSE train = 1.5482920985791055
iter = 60 , loss = 1.1986042115474145 , RMSE train = 1.5482920985791055
iter = 70 , loss = 1.1986042112638495 , RMSE train = 1.5482920985791055
iter = 80 , loss = 1.1986042112612691 , RMSE train = 1.5482920985791055
iter = 90 , loss = 1.1986042112612456 , RMSE train = 1.5482920985791055
iter = 100 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055
iter = 110 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055
iter = 120 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055
iter = 130 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055
iter = 140 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055
iter = 150 , loss = 1.1986042112612454 , RMSE train = 1.5482920985791055

User-based MF, RMSE = 3.3121502202189936


iter = 10 , loss = 5.737639909461726 , RMSE train = 1.5153838687075403
iter = 20 , loss = 1.1899809105139005 , RMSE train = 1.5154111501959246
iter = 30 , loss = 1.1486152284769728 , RMSE train = 1.5154111549832605
iter = 40 , loss = 1.148238938998317 , RMSE train = 1.5154111549838647
iter = 50 , loss = 1.1482355157557056 , RMSE train = 1.5154111549838647
iter = 60 , loss = 1.1482354846107503 , RMSE train = 1.5154111549838647
iter = 70 , loss = 1.1482354843273679 , RMSE train = 1.5154111549838647
iter = 80 , loss = 1.1482354843247893 , RMSE train = 1.5154111549838647
iter = 90 , loss = 1.1482354843247657 , RMSE train = 1.5154111549838647
iter = 100 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647
iter = 110 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647
iter = 120 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647
iter = 130 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647
iter = 140 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647
iter = 150 , loss = 1.1482354843247655 , RMSE train = 1.5154111549838647

User-based MF, RMSE = 3.226492891017998


iter = 10 , loss = 5.588926153101002 , RMSE train = 1.4115910765216377
iter = 20 , loss = 1.0381096201834266 , RMSE train = 1.411620118301499
iter = 30 , loss = 0.9967156811004545 , RMSE train = 1.4116201230495116
iter = 40 , loss = 0.9963391427450295 , RMSE train = 1.4116201230500938
iter = 50 , loss = 0.9963357173493096 , RMSE train = 1.4116201230500938
iter = 60 , loss = 0.9963356861861173 , RMSE train = 1.4116201230500938
iter = 70 , loss = 0.9963356859025845 , RMSE train = 1.4116201230500938
iter = 80 , loss = 0.9963356859000045 , RMSE train = 1.4116201230500938
iter = 90 , loss = 0.9963356858999811 , RMSE train = 1.4116201230500938
iter = 100 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938
iter = 110 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938
iter = 120 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938
iter = 130 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938
iter = 140 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938
iter = 150 , loss = 0.9963356858999809 , RMSE train = 1.4116201230500938

User-based MF, RMSE = 3.172974460579289

User-based MF-5models, RMSE = 2.202130817572402

################################################################################

K = 100, lam = .5, learning_rate = 0.75, max_iter = 200, user_based = 0



