{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Neighborhood-Based_RS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXi4YZehyvuQ",
        "colab_type": "code",
        "outputId": "b3661a9b-3387-4136-99cb-2c9374cc6e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/Thesis', force_remount= True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /Thesis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXif1-xG0TuZ",
        "colab_type": "code",
        "outputId": "0de7fa6b-ffee-4224-d017-e6230944a8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/Thesis/My Drive/Oh_Our_Thesis/recommender-system\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Thesis/My Drive/Oh_Our_Thesis/recommender-system\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMBMTpA1yuAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import sparse \n",
        "\n",
        "class CF(object):\n",
        "    \"\"\"docstring for CF\"\"\"\n",
        "    def __init__(self, Y_data, k, dist_func = cosine_similarity, uuCF = 1):\n",
        "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
        "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]\n",
        "        # self.Y_data = self.Y_data.astype(float)\n",
        "        self.k = k\n",
        "        self.dist_func = dist_func\n",
        "        self.Ybar_data = None \n",
        "        \n",
        "        # number of users and items. Remember to add 1 since id starts from 0\n",
        "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1 \n",
        "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
        "\n",
        "        # self.n_users = len(set(self.Y_data[:, 0])) +1\n",
        "        # self.n_items = len(set(self.Y_data[:, 1])) +1\n",
        "        \n",
        "    \n",
        "    def add(self, new_data):\n",
        "        \"\"\"\n",
        "        Update Y_data matrix when new ratings come.\n",
        "        For simplicity, suppose that there is no new user or item.\n",
        "        \"\"\"\n",
        "        self.Y_data = np.concatenate((self.Y_data, new_data), axis = 0)\n",
        "    \n",
        "    def normalize_Y(self):\n",
        "        users = self.Y_data[:, 0] # all users - first col of the Y_data\n",
        "        self.Ybar_data = self.Y_data.copy()\n",
        "        self.mu = np.zeros((self.n_users,))\n",
        "        for n in range(self.n_users):\n",
        "            # row indices of rating done by user n\n",
        "            # since indices need to be integers, we need to convert\n",
        "            ids = np.where(users == n)[0].astype(np.int32)\n",
        "            # indices of all ratings associated with user n\n",
        "            item_ids = self.Y_data[ids, 1] \n",
        "            # and the corresponding ratings \n",
        "            ratings = self.Y_data[ids, 2]\n",
        "            # take mean\n",
        "            ###\n",
        "            # ratings = ratings.astype(float)\n",
        "            ###\n",
        "            m = np.mean(ratings) \n",
        "            if np.isnan(m):\n",
        "                m = 0 # to avoid empty array and nan value\n",
        "            self.mu[n] = m\n",
        "            # normalize\n",
        "            self.Ybar_data[ids, 2] = ratings - self.mu[n]\n",
        "\n",
        "        ################################################\n",
        "        # form the rating matrix as a sparse matrix. Sparsity is important \n",
        "        # for both memory and computing efficiency. For example, if #user = 1M, \n",
        "        # #item = 100k, then shape of the rating matrix would be (100k, 1M), \n",
        "        # you may not have enough memory to store this. Then, instead, we store \n",
        "        # nonzeros only, and, of course, their locations.\n",
        "\n",
        "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
        "            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
        "        self.Ybar = self.Ybar.tocsr()\n",
        "\n",
        "    def similarity(self):\n",
        "        eps = 1e-6\n",
        "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
        "    \n",
        "        \n",
        "    def refresh(self):\n",
        "        \"\"\"\n",
        "        Normalize data and calculate similarity matrix again (after\n",
        "        some few ratings added)\n",
        "        \"\"\"\n",
        "        self.normalize_Y()\n",
        "        self.similarity() \n",
        "        \n",
        "    def fit(self):\n",
        "        self.refresh()\n",
        "        \n",
        "    \n",
        "    def __pred(self, u, i, normalized = 1):\n",
        "        \"\"\" \n",
        "        predict the rating of user u for item i (normalized)\n",
        "        if you need the un\n",
        "        \"\"\"\n",
        "        u = u.astype(int)\n",
        "        i = i.astype(int)\n",
        "        # Step 1: find all users who rated i\n",
        "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
        "        # Step 2: |\n",
        "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
        "        # Step 3: find similarity btw the current user and others \n",
        "        # who already rated i\n",
        "        sim = self.S[u, users_rated_i]\n",
        "        # Step 4: find the k most similarity users\n",
        "        a = np.argsort(sim)[-self.k:] \n",
        "        # and the corresponding similarity levels\n",
        "        nearest_s = sim[a]\n",
        "        # How did each of 'near' users rated item i\n",
        "        r = self.Ybar[i, users_rated_i[a]]\n",
        "        if normalized:\n",
        "            # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
        "            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
        "\n",
        "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]\n",
        "    \n",
        "    def pred(self, u, i, normalized = 1):\n",
        "        \"\"\" \n",
        "        predict the rating of user u for item i (normalized)\n",
        "        if you need the un\n",
        "        \"\"\"\n",
        "        if self.uuCF: return self.__pred(u, i, normalized)\n",
        "        return self.__pred(i, u, normalized)\n",
        "            \n",
        "    \n",
        "    def recommend(self, u):\n",
        "        \"\"\"\n",
        "        Determine all items should be recommended for user u.\n",
        "        The decision is made based on all i such that:\n",
        "        self.pred(u, i) > 0. Suppose we are considering items which \n",
        "        have not been rated by u yet. \n",
        "        \"\"\"\n",
        "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
        "        items_rated_by_u = self.Y_data[ids, 1].tolist()              \n",
        "        recommended_items = []\n",
        "        for i in range(self.n_items):\n",
        "            if i not in items_rated_by_u:\n",
        "                rating = self.__pred(u, i)\n",
        "                if rating > 0: \n",
        "                    recommended_items.append(i)\n",
        "        \n",
        "        return recommended_items \n",
        "    \n",
        "    def recommend2(self, u):\n",
        "        \"\"\"\n",
        "        Determine all items should be recommended for user u.\n",
        "        The decision is made based on all i such that:\n",
        "        self.pred(u, i) > 0. Suppose we are considering items which \n",
        "        have not been rated by u yet. \n",
        "        \"\"\"\n",
        "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
        "        items_rated_by_u = self.Y_data[ids, 1].tolist()              \n",
        "        recommended_items = []\n",
        "    \n",
        "        for i in range(self.n_items):\n",
        "            if i not in items_rated_by_u:\n",
        "                rating = self.__pred(u, i)\n",
        "                if rating > 0: \n",
        "                    recommended_items.append(i)\n",
        "        \n",
        "        return recommended_items \n",
        "\n",
        "    def print_recommendation(self):\n",
        "        \"\"\"\n",
        "        print all items which should be recommended for each user \n",
        "        \"\"\"\n",
        "        print ('Recommendation: ')\n",
        "        for u in range(self.n_users):\n",
        "            recommended_items = self.recommend(u)\n",
        "            if self.uuCF:\n",
        "                print ('    Recommend item(s):', recommended_items, 'for user', u)\n",
        "            else: \n",
        "                print ('    Recommend item', u, 'for user(s) : ', recommended_items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OeUuQFg2yuBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = pd.read_json('../Crawl_Data/user_rates_place-ver2.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmfE0sQ1-Vqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings_x = tmp[['User_Id','Place_Id','Rating']]\n",
        "userId = ratings_x.User_Id.unique()\n",
        "userId.sort()\n",
        "mapUserId  = {}\n",
        "for i, value in enumerate(userId):\n",
        "  mapUserId[value] = i\n",
        "\n",
        "placeId = ratings_x.Place_Id.unique()\n",
        "placeId.sort()\n",
        "mapPlaceId  = {}\n",
        "for i, value in enumerate(placeId):\n",
        "  mapPlaceId[value] = i\n",
        "\n",
        "tmp_based = ratings_x.values\n",
        "\n",
        "for i in range(len(tmp_based[:,0])):\n",
        "  tmp_based[i][0] = mapUserId[tmp_based [i][0]]\n",
        "for i in range(len(tmp_based[:,1])):\n",
        "  tmp_based[i][1] = mapPlaceId[tmp_based [i][1]]\n",
        "\n",
        "tmp_based_copy = tmp_based"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SLs-Lbx6yuBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tmp_based_copy = tmp_based_copy[tmp_based_copy[:,0].argsort()] # sort theo  user_id\n",
        "based_train = []\n",
        "based_test = []\n",
        "_usersId = (tmp_based_copy[:, 0]).astype(np.int32)\n",
        "\n",
        "for i in range((max(tmp_based_copy[:,0])).astype(int)):  \n",
        "  _ids = np.where(_usersId == i)[0].astype(np.int32)\n",
        "  if (len(_ids) > 4):\n",
        "    X_train, X_test= train_test_split(tmp_based_copy[_ids], test_size=.2, random_state=42)\n",
        "    based_train += X_train.tolist()\n",
        "    based_test += X_test.tolist()\n",
        "    \n",
        "based_train = np.array(based_train)\n",
        "based_test = np.array(based_test)\n",
        "# X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "B-rgw0avyuBl",
        "colab_type": "code",
        "outputId": "9d6d28f4-dad3-4dd7-bcd5-944182134521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "rs = CF(based_train, k = 30, uuCF = 0)\n",
        "rs.fit()\n",
        "# rs.print_recommendation()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQpTN0cJO4es",
        "colab_type": "code",
        "outputId": "0d7dea9c-5153-4972-d98b-cbe0a1bd1b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_tests = based_test.shape[0]\n",
        "SE = 0 # squared error\n",
        "for n in range(n_tests):\n",
        "    pred = rs.pred(based_test[n, 0], based_test[n, 1], normalized = 0)\n",
        "    SE += (pred - based_test[n, 2])**2 \n",
        "\n",
        "RMSE = np.sqrt(SE/n_tests)\n",
        "print ('User-user CF, RMSE =', RMSE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User-user CF, RMSE = 3.139806359296359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H10Y_d4VUdXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}